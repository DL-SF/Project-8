Mixed reality systems need to track users in real-world to project the illusion of 
“reality”. Multi-modal sensory data acquired from a MR headset (such as Hololens) is used for 
tracking the user in its MR world. Primarily, two kinds of data - inertial and visual - serve as data 
sources for tracking. Sensor fusion techniques stitch these data sources from the 9D inertial data 
and cameras (visual data) to track the user and provide spatial services..


Previously, various other sensor fusion techniques have been developed such as  Kalman Filter, Convolutional Neural Networks,
Bayesian Networks, Dempster Shafer and Central Limit Theorem.
